# K12è‹±è¯­çŸ¥è¯†å›¾è°±ç³»ç»Ÿå¼€å‘æ–‡æ¡£

## ğŸ“‹ ç›®å½•
- [é¡¹ç›®æ¦‚è¿°](#é¡¹ç›®æ¦‚è¿°)
- [ç³»ç»Ÿæ¶æ„](#ç³»ç»Ÿæ¶æ„)
- [å¼€å‘ç¯å¢ƒæ­å»º](#å¼€å‘ç¯å¢ƒæ­å»º)
- [æ ¸å¿ƒæ¨¡å—è¯¦è§£](#æ ¸å¿ƒæ¨¡å—è¯¦è§£)
- [APIæ¥å£æ–‡æ¡£](#apiæ¥å£æ–‡æ¡£)
- [AI Agentå¼€å‘æŒ‡å—](#ai-agentå¼€å‘æŒ‡å—)
- [æ•°æ®åº“è®¾è®¡](#æ•°æ®åº“è®¾è®¡)
- [å‰ç«¯å¼€å‘æŒ‡å—](#å‰ç«¯å¼€å‘æŒ‡å—)
- [æµ‹è¯•æŒ‡å—](#æµ‹è¯•æŒ‡å—)
- [éƒ¨ç½²æŒ‡å—](#éƒ¨ç½²æŒ‡å—)
- [æ€§èƒ½ä¼˜åŒ–](#æ€§èƒ½ä¼˜åŒ–)
- [æ•…éšœæ’æŸ¥](#æ•…éšœæ’æŸ¥)

## é¡¹ç›®æ¦‚è¿°

### ğŸ¯ é¡¹ç›®ç›®æ ‡
æ„å»ºä¸€ä¸ªåŸºäºçŸ¥è¯†å›¾è°±çš„K12è‹±è¯­é¢˜åº“æ™ºèƒ½æ ‡æ³¨ä¸åˆ†æç³»ç»Ÿï¼Œå®ç°é¢˜ç›®ä¸çŸ¥è¯†ç‚¹çš„ç²¾å‡†å…³è”ï¼Œæä¾›æ™ºèƒ½æ¨èå’Œå­¦æƒ…åˆ†æåŠŸèƒ½ã€‚

### ğŸ—ï¸ æ ¸å¿ƒç‰¹æ€§
- **çŸ¥è¯†å›¾è°±æ„å»º**: åŸºäºNeo4jçš„å›¾æ•°æ®åº“å­˜å‚¨çŸ¥è¯†ç‚¹å…³ç³»
- **AIæ™ºèƒ½æ ‡æ³¨**: è‡ªåŠ¨è¯†åˆ«é¢˜ç›®å¯¹åº”çš„çŸ¥è¯†ç‚¹
- **å­¦æƒ…åˆ†æ**: åŸºäºç­”é¢˜æ•°æ®çš„è–„å¼±çŸ¥è¯†ç‚¹åˆ†æ
- **ä¸ªæ€§åŒ–æ¨è**: æ™ºèƒ½å­¦ä¹ è·¯å¾„è§„åˆ’
- **å¯è§†åŒ–ç•Œé¢**: ç°ä»£åŒ–Webç•Œé¢å±•ç¤º

### ğŸ› ï¸ æŠ€æœ¯æ ˆ
- **åç«¯**: Python 3.8+, FastAPI, Neo4j
- **å‰ç«¯**: HTML5, CSS3, JavaScript, Bootstrap 5
- **AI/NLP**: jieba, scikit-learn, è‡ªå®šä¹‰NLPç®—æ³•
- **æ•°æ®åº“**: Neo4j 4.0+ (å›¾æ•°æ®åº“)
- **éƒ¨ç½²**: Uvicorn, Docker (å¯é€‰)

## ç³»ç»Ÿæ¶æ„

### ğŸ›ï¸ å››å±‚æ¶æ„è®¾è®¡

```mermaid
graph TD
    A[è¡¨ç¤ºå±‚ - Webç•Œé¢] --> B[åº”ç”¨å±‚ - FastAPI]
    B --> C[æœåŠ¡å±‚ - ä¸šåŠ¡é€»è¾‘]
    C --> D[æ•°æ®å±‚ - Neo4jå›¾æ•°æ®åº“]
    
    subgraph "æœåŠ¡å±‚ç»„ä»¶"
        C1[AI AgentæœåŠ¡]
        C2[NLPå¤„ç†æœåŠ¡]
        C3[æ•°æ®åˆ†ææœåŠ¡]
        C4[æ•°æ®åº“æœåŠ¡]
    end
```

### ğŸ“ é¡¹ç›®ç»“æ„
```
è‹±è¯­çŸ¥è¯†å›¾åº“/
â”œâ”€â”€ backend/                    # åç«¯ä»£ç 
â”‚   â”œâ”€â”€ api/                   # APIå±‚
â”‚   â”‚   â”œâ”€â”€ main.py           # FastAPIä¸»åº”ç”¨
â”‚   â”‚   â””â”€â”€ routes/           # APIè·¯ç”±
â”‚   â”‚       â”œâ”€â”€ knowledge_routes.py    # çŸ¥è¯†ç‚¹API
â”‚   â”‚       â”œâ”€â”€ question_routes.py     # é¢˜ç›®API
â”‚   â”‚       â”œâ”€â”€ annotation_routes.py   # æ ‡æ³¨API
â”‚   â”‚       â”œâ”€â”€ analytics_routes.py    # åˆ†æAPI
â”‚   â”‚       â””â”€â”€ ai_agent_routes.py     # AI Agent API
â”‚   â”œâ”€â”€ models/               # æ•°æ®æ¨¡å‹
â”‚   â”‚   â””â”€â”€ schema.py         # å›¾æ•°æ®åº“Schemaå®šä¹‰
â”‚   â”œâ”€â”€ services/             # ä¸šåŠ¡æœåŠ¡å±‚
â”‚   â”‚   â”œâ”€â”€ database.py       # æ•°æ®åº“æ“ä½œæœåŠ¡
â”‚   â”‚   â”œâ”€â”€ nlp_service.py    # NLPå¤„ç†æœåŠ¡
â”‚   â”‚   â”œâ”€â”€ ai_agent_service.py # AI AgentæœåŠ¡
â”‚   â”‚   â””â”€â”€ analytics_service.py # æ•°æ®åˆ†ææœåŠ¡
â”‚   â””â”€â”€ utils/                # å·¥å…·ç±»
â”œâ”€â”€ frontend/                 # å‰ç«¯ä»£ç 
â”‚   â”œâ”€â”€ static/              # é™æ€èµ„æº
â”‚   â”‚   â”œâ”€â”€ css/            # æ ·å¼æ–‡ä»¶
â”‚   â”‚   â””â”€â”€ js/             # JavaScriptæ–‡ä»¶
â”‚   â””â”€â”€ templates/           # HTMLæ¨¡æ¿
â”œâ”€â”€ data/                    # æ•°æ®æ–‡ä»¶
â”‚   â”œâ”€â”€ knowledge_base/      # çŸ¥è¯†ç‚¹æ•°æ®
â”‚   â””â”€â”€ sample_questions/    # ç¤ºä¾‹é¢˜ç›®
â”œâ”€â”€ scripts/                 # å·¥å…·è„šæœ¬
â”‚   â”œâ”€â”€ init_database.py     # æ•°æ®åº“åˆå§‹åŒ–
â”‚   â”œâ”€â”€ load_sample_data.py  # ç¤ºä¾‹æ•°æ®åŠ è½½
â”‚   â”œâ”€â”€ test_system.py       # ç³»ç»Ÿæµ‹è¯•
â”‚   â””â”€â”€ test_ai_agent.py     # AI Agentæµ‹è¯•
â”œâ”€â”€ requirements.txt         # Pythonä¾èµ–
â”œâ”€â”€ config.env              # é…ç½®æ–‡ä»¶
â”œâ”€â”€ run.py                  # å¯åŠ¨è„šæœ¬
â”œâ”€â”€ README.md               # é¡¹ç›®è¯´æ˜
â”œâ”€â”€ INSTALL.md              # å®‰è£…æŒ‡å—
â””â”€â”€ DEVELOPMENT.md          # å¼€å‘æ–‡æ¡£
```

## å¼€å‘ç¯å¢ƒæ­å»º

### ğŸ“¦ ç¯å¢ƒè¦æ±‚
- Python 3.8+
- Neo4j 4.0+
- Node.js 14+ (å¯é€‰ï¼Œç”¨äºå‰ç«¯æ„å»ºå·¥å…·)
- 8GB+ å†…å­˜æ¨è

### ğŸš€ å¿«é€Ÿå¼€å§‹
```bash
# 1. å…‹éš†é¡¹ç›®
git clone <repository-url>
cd è‹±è¯­çŸ¥è¯†å›¾åº“

# 2. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python -m venv venv
source venv/bin/activate  # Linux/Mac
# æˆ– venv\Scripts\activate  # Windows

# 3. å®‰è£…ä¾èµ–
pip install -r requirements.txt

# 4. å®‰è£…å¹¶å¯åŠ¨Neo4j
brew install neo4j  # Mac
brew services start neo4j

# 5. é…ç½®ç¯å¢ƒ
cp config.env.example config.env
# ç¼–è¾‘config.envè®¾ç½®æ•°æ®åº“å¯†ç 

# 6. åˆå§‹åŒ–æ•°æ®åº“
python scripts/init_database.py
python scripts/load_sample_data.py

# 7. å¯åŠ¨ç³»ç»Ÿ
python run.py
```

### ğŸ”§ å¼€å‘å·¥å…·æ¨è
- **IDE**: VSCode, PyCharm
- **APIæµ‹è¯•**: Postman, Insomnia
- **æ•°æ®åº“å®¢æˆ·ç«¯**: Neo4j Desktop, Neo4j Browser
- **ç‰ˆæœ¬æ§åˆ¶**: Git
- **ä»£ç æ ¼å¼åŒ–**: Black, Prettier

## æ ¸å¿ƒæ¨¡å—è¯¦è§£

### ğŸ§  AI AgentæœåŠ¡ (ai_agent_service.py)

AI Agentæ˜¯ç³»ç»Ÿçš„æ ¸å¿ƒæ™ºèƒ½ç»„ä»¶ï¼Œè´Ÿè´£è‡ªåŠ¨æ ‡æ³¨åŠŸèƒ½ã€‚

#### ä¸»è¦åŠŸèƒ½
```python
class AIAgentService:
    def __init__(self):
        self.confidence_threshold = 0.3  # ç½®ä¿¡åº¦é˜ˆå€¼
        self.max_auto_annotations = 5    # æœ€å¤§è‡ªåŠ¨æ ‡æ³¨æ•°
        self.learning_enabled = True     # å­¦ä¹ åŠŸèƒ½å¼€å…³
    
    async def auto_annotate_question(self, question: Question) -> Dict[str, Any]:
        """è‡ªåŠ¨æ ‡æ³¨å•ä¸ªé¢˜ç›®"""
        
    async def batch_auto_annotate(self, questions: List[Question]) -> Dict[str, Any]:
        """æ‰¹é‡è‡ªåŠ¨æ ‡æ³¨"""
        
    def update_configuration(self, config: Dict[str, Any]):
        """æ›´æ–°AI Agenté…ç½®"""
```

#### å†³ç­–ç®—æ³•
AI Agentä½¿ç”¨å¤šå› ç´ å†³ç­–ç®—æ³•ï¼š

1. **åŸºç¡€ç½®ä¿¡åº¦**: NLPæ¨¡å‹è¾“å‡ºçš„åŸå§‹ç½®ä¿¡åº¦
2. **é¢˜ç›®ç±»å‹åŠ æƒ**: æ ¹æ®é¢˜ç›®ç±»å‹è°ƒæ•´æƒé‡
3. **å…³é”®è¯åŒ¹é…åŠ æƒ**: åŸºäºå…³é”®è¯åŒ¹é…å¯†åº¦
4. **å†å²å‡†ç¡®ç‡åŠ æƒ**: åŸºäºç”¨æˆ·åé¦ˆçš„å†å²æ•°æ®
5. **éš¾åº¦åŒ¹é…åŠ æƒ**: é¢˜ç›®éš¾åº¦ä¸çŸ¥è¯†ç‚¹å¤æ‚åº¦åŒ¹é…
6. **è¿‡åº¦æ ‡æ³¨æƒ©ç½š**: é¿å…ç»™å•ä¸ªé¢˜ç›®æ ‡æ³¨è¿‡å¤šçŸ¥è¯†ç‚¹

#### é…ç½®å‚æ•°
```python
# é…ç½®ç¤ºä¾‹
config = {
    "confidence_threshold": 0.3,    # è‡ªåŠ¨åº”ç”¨çš„æœ€ä½ç½®ä¿¡åº¦
    "max_auto_annotations": 5,      # æ¯é¢˜æœ€å¤šè‡ªåŠ¨æ ‡æ³¨æ•°
    "learning_enabled": True        # æ˜¯å¦å¯ç”¨å­¦ä¹ åŠŸèƒ½
}
```

### ğŸ” NLPæœåŠ¡ (nlp_service.py)

è´Ÿè´£è‡ªç„¶è¯­è¨€å¤„ç†å’ŒçŸ¥è¯†ç‚¹æ¨èã€‚

#### æ ¸å¿ƒç®—æ³•
```python
class NLPService:
    def suggest_knowledge_points(self, question_content: str, question_type: str) -> List[Dict]:
        """çŸ¥è¯†ç‚¹æ¨èä¸»å‡½æ•°"""
        # 1. å…³é”®è¯åŒ¹é…
        # 2. è¯­ä¹‰ç›¸ä¼¼åº¦è®¡ç®—
        # 3. é¢˜ç›®ç±»å‹åˆ†æ
        # 4. ç»¼åˆè¯„åˆ†æ’åº
```

#### å…³é”®è¯åº“
ç³»ç»Ÿç»´æŠ¤äº†ä¸€ä¸ªè¯¦ç»†çš„å…³é”®è¯æ¨¡å¼åº“ï¼š
```python
keyword_patterns = {
    "ä¸€èˆ¬ç°åœ¨æ—¶": [
        "always", "usually", "often", "sometimes", "never",
        "every day", "every week", "æ€»æ˜¯", "é€šå¸¸", "ç»å¸¸"
    ],
    "ä¸€èˆ¬è¿‡å»æ—¶": [
        "yesterday", "last week", "ago", "æ˜¨å¤©", "ä¸Šå‘¨", "ä»¥å‰"
    ],
    # ... æ›´å¤šçŸ¥è¯†ç‚¹
}
```

### ğŸ“Š æ•°æ®åˆ†ææœåŠ¡ (analytics_service.py)

æä¾›å„ç§æ•°æ®åˆ†æå’Œç»Ÿè®¡åŠŸèƒ½ã€‚

#### ä¸»è¦åˆ†æç±»å‹
```python
class AnalyticsService:
    def get_knowledge_coverage_analysis(self) -> Dict:
        """çŸ¥è¯†ç‚¹è¦†ç›–åˆ†æ"""
        
    def get_difficulty_distribution(self) -> Dict:
        """é¢˜ç›®éš¾åº¦åˆ†å¸ƒ"""
        
    def analyze_student_weak_points(self, student_answers: List) -> Dict:
        """å­¦ç”Ÿè–„å¼±ç‚¹åˆ†æ"""
        
    def generate_learning_path_recommendation(self, targets: List) -> Dict:
        """å­¦ä¹ è·¯å¾„æ¨è"""
```

### ğŸ—„ï¸ æ•°æ®åº“æœåŠ¡ (database.py)

å°è£…æ‰€æœ‰Neo4jæ•°æ®åº“æ“ä½œã€‚

#### è¿æ¥ç®¡ç†
```python
class Neo4jService:
    def connect(self) -> bool:
        """è¿æ¥æ•°æ®åº“"""
        
    def close(self):
        """å…³é—­è¿æ¥"""
        
    def initialize_database(self):
        """åˆå§‹åŒ–æ•°æ®åº“ç»“æ„"""
```

#### æ•°æ®æ“ä½œ
```python
# çŸ¥è¯†ç‚¹æ“ä½œ
def create_knowledge_point(self, kp: KnowledgePoint) -> str
def get_knowledge_point(self, kp_id: str) -> Optional[Dict]
def search_knowledge_points(self, keyword: str) -> List[Dict]

# é¢˜ç›®æ“ä½œ
def create_question(self, question: Question) -> str
def link_question_to_knowledge(self, question_id: str, kp_id: str, weight: float)

# å¤æ‚æŸ¥è¯¢
def find_questions_by_knowledge_point(self, kp_name: str) -> List[Dict]
def get_knowledge_hierarchy(self) -> List[Dict]
```

## APIæ¥å£æ–‡æ¡£

### ğŸŒ åŸºç¡€ä¿¡æ¯
- **Base URL**: `http://localhost:8000`
- **APIæ–‡æ¡£**: `http://localhost:8000/docs`
- **è®¤è¯**: æš‚æ—  (å¼€å‘ç‰ˆæœ¬)
- **æ•°æ®æ ¼å¼**: JSON

### ğŸ“ çŸ¥è¯†ç‚¹ç®¡ç†API

#### åˆ›å»ºçŸ¥è¯†ç‚¹
```http
POST /api/knowledge/
Content-Type: application/json

{
    "name": "ç°åœ¨å®Œæˆæ—¶",
    "description": "è¡¨ç¤ºè¿‡å»å‘ç”Ÿçš„åŠ¨ä½œå¯¹ç°åœ¨é€ æˆçš„å½±å“",
    "level": "åˆä¸­ä¸€å¹´çº§",
    "difficulty": "medium",
    "keywords": ["have", "has", "è¿‡å»åˆ†è¯"]
}
```

#### æœç´¢çŸ¥è¯†ç‚¹
```http
GET /api/knowledge/search?keyword=æ—¶æ€
```

#### è·å–çŸ¥è¯†ç‚¹è¯¦æƒ…
```http
GET /api/knowledge/{kp_id}
```

#### åˆ›å»ºçŸ¥è¯†ç‚¹å±‚çº§å…³ç³»
```http
POST /api/knowledge/{parent_id}/children/{child_id}
```

### ğŸ“š é¢˜ç›®ç®¡ç†API

#### åˆ›å»ºé¢˜ç›®
```http
POST /api/questions/
Content-Type: application/json

{
    "content": "She _____ to school every day.",
    "question_type": "é€‰æ‹©é¢˜",
    "options": ["go", "goes", "going", "gone"],
    "answer": "B",
    "analysis": "ä¸»è¯­æ˜¯ç¬¬ä¸‰äººç§°å•æ•°ï¼Œç”¨goes",
    "difficulty": "easy"
}
```

#### å…³è”çŸ¥è¯†ç‚¹
```http
POST /api/questions/{question_id}/knowledge/{kp_id}?weight=0.8
```

#### æ ¹æ®çŸ¥è¯†ç‚¹æŸ¥æ‰¾é¢˜ç›®
```http
GET /api/questions/by-knowledge/{kp_name}
```

### ğŸ¤– AI Agent API

#### è‡ªåŠ¨æ ‡æ³¨å•ä¸ªé¢˜ç›®
```http
POST /api/ai-agent/auto-annotate
Content-Type: application/json

{
    "question": {
        "content": "Tom plays basketball every day.",
        "question_type": "é€‰æ‹©é¢˜",
        "answer": "ä¸€èˆ¬ç°åœ¨æ—¶"
    }
}
```

**å“åº”ç¤ºä¾‹**:
```json
{
    "question_id": "q_123456",
    "suggestions": [
        {
            "knowledge_point_id": "kp_588066",
            "knowledge_point_name": "ä¸€èˆ¬ç°åœ¨æ—¶",
            "confidence": 0.85,
            "reason": "åŒ¹é…å…³é”®è¯: every day, plays"
        }
    ],
    "auto_annotations": [...],
    "applied_annotations": [...],
    "status": "completed"
}
```

#### æ‰¹é‡è‡ªåŠ¨æ ‡æ³¨
```http
POST /api/ai-agent/batch-auto-annotate
Content-Type: application/json

{
    "questions": [
        {
            "content": "She is reading now.",
            "question_type": "é€‰æ‹©é¢˜",
            "answer": "is reading"
        }
    ]
}
```

#### æ™ºèƒ½å¯¼å…¥
```http
POST /api/ai-agent/smart-import
Content-Type: application/json

[
    {
        "content": "I went to school yesterday.",
        "question_type": "é€‰æ‹©é¢˜",
        "answer": "went",
        "difficulty": "easy"
    }
]
```

#### é…ç½®AI Agent
```http
PUT /api/ai-agent/config
Content-Type: application/json

{
    "confidence_threshold": 0.5,
    "max_auto_annotations": 3,
    "learning_enabled": true
}
```

#### è§¦å‘è‡ªåŠ¨æ ‡æ³¨
```http
POST /api/ai-agent/trigger-auto-annotation/{question_id}
```

### ğŸ“Š æ•°æ®åˆ†æAPI

#### çŸ¥è¯†ç‚¹è¦†ç›–åˆ†æ
```http
GET /api/analytics/coverage
```

#### éš¾åº¦åˆ†å¸ƒåˆ†æ
```http
GET /api/analytics/difficulty-distribution
```

#### è–„å¼±ç‚¹åˆ†æ
```http
POST /api/analytics/weak-points
Content-Type: application/json

{
    "student_answers": [
        {"question_id": "q_123", "is_correct": false},
        {"question_id": "q_124", "is_correct": true}
    ]
}
```

#### å­¦ä¹ è·¯å¾„æ¨è
```http
POST /api/analytics/learning-path
Content-Type: application/json

{
    "target_knowledge_points": ["ç°åœ¨å®Œæˆæ—¶", "è¢«åŠ¨è¯­æ€"]
}
```

#### ç»¼åˆæŠ¥å‘Š
```http
GET /api/analytics/comprehensive-report
```

### ğŸ·ï¸ æ ‡æ³¨ç®¡ç†API

#### è·å–æ ‡æ³¨å»ºè®®
```http
POST /api/annotation/suggest
Content-Type: application/json

{
    "question_content": "She has finished her homework.",
    "question_type": "é€‰æ‹©é¢˜"
}
```

#### æäº¤æ ‡æ³¨ç»“æœ
```http
POST /api/annotation/submit?question_id=q_123
Content-Type: application/json

[
    {
        "knowledge_point_id": "kp_456",
        "weight": 0.9
    }
]
```

### ğŸ“ˆ ç³»ç»Ÿç›‘æ§API

#### å¥åº·æ£€æŸ¥
```http
GET /health
```

#### ä»ªè¡¨æ¿ç»Ÿè®¡
```http
GET /api/analytics/dashboard-stats
```

## AI Agentå¼€å‘æŒ‡å—

### ğŸ§¬ æ ¸å¿ƒç®—æ³•åŸç†

#### 1. å¤šå› ç´ å†³ç­–æ¨¡å‹
```python
def _calculate_decision_score(self, question, suggestion, base_confidence):
    score = base_confidence
    
    # é¢˜ç›®ç±»å‹åŒ¹é…åŠ æƒ
    score += self._get_question_type_boost(question.question_type, suggestion.kp_name)
    
    # å…³é”®è¯åŒ¹é…åŠ æƒ
    score += self._get_keyword_match_boost(question.content, suggestion.keywords)
    
    # å†å²å‡†ç¡®ç‡åŠ æƒ
    score += self._get_historical_accuracy_boost(suggestion.kp_id, question.question_type)
    
    # éš¾åº¦åŒ¹é…åŠ æƒ
    score += self._get_difficulty_match_boost(question.difficulty, suggestion.kp_name)
    
    # è¿‡åº¦æ ‡æ³¨æƒ©ç½š
    score -= self._get_over_annotation_penalty(question)
    
    return max(0.0, min(1.0, score))
```

#### 2. å…³é”®è¯åŒ¹é…ç®—æ³•
```python
def _keyword_matching_score(self, question_text, knowledge_point):
    patterns = self.keyword_patterns[knowledge_point]
    matched_keywords = []
    score = 0.0
    
    for pattern in patterns:
        if pattern.lower() in question_text.lower():
            matched_keywords.append(pattern)
            # é•¿å…³é”®è¯æƒé‡æ›´é«˜
            score += 2.0 if len(pattern) > 5 else 1.0
    
    # å½’ä¸€åŒ–
    max_score = len(patterns) * 2.0
    normalized_score = min(score / max_score, 1.0) if max_score > 0 else 0.0
    
    return normalized_score, matched_keywords
```

#### 3. è¯­ä¹‰ç›¸ä¼¼åº¦è®¡ç®—
```python
def _semantic_similarity_score(self, question_text, kp_description):
    try:
        texts = [question_text, kp_description]
        vectorizer = TfidfVectorizer()
        tfidf_matrix = vectorizer.fit_transform(texts)
        similarity = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])[0][0]
        return float(similarity)
    except Exception:
        return 0.0
```

### ğŸ›ï¸ é…ç½®å‚æ•°è¯¦è§£

#### confidence_threshold (ç½®ä¿¡åº¦é˜ˆå€¼)
- **èŒƒå›´**: 0.1 - 1.0
- **é»˜è®¤å€¼**: 0.3
- **è¯´æ˜**: åªæœ‰ç½®ä¿¡åº¦è¶…è¿‡æ­¤é˜ˆå€¼çš„æ ‡æ³¨æ‰ä¼šè¢«è‡ªåŠ¨åº”ç”¨
- **è°ƒä¼˜å»ºè®®**: 
  - æé«˜é˜ˆå€¼ â†’ æ›´ä¿å®ˆï¼Œå‡†ç¡®ç‡é«˜ä½†è¦†ç›–ç‡ä½
  - é™ä½é˜ˆå€¼ â†’ æ›´æ¿€è¿›ï¼Œè¦†ç›–ç‡é«˜ä½†å¯èƒ½æœ‰è¯¯æ ‡

#### max_auto_annotations (æœ€å¤§è‡ªåŠ¨æ ‡æ³¨æ•°)
- **èŒƒå›´**: 1 - 10
- **é»˜è®¤å€¼**: 5
- **è¯´æ˜**: æ¯é“é¢˜ç›®æœ€å¤šè‡ªåŠ¨æ ‡æ³¨çš„çŸ¥è¯†ç‚¹æ•°é‡
- **è°ƒä¼˜å»ºè®®**: æ ¹æ®é¢˜ç›®å¤æ‚åº¦è°ƒæ•´ï¼Œç®€å•é¢˜ç›®ç”¨è¾ƒå°å€¼

#### learning_enabled (å­¦ä¹ åŠŸèƒ½)
- **ç±»å‹**: Boolean
- **é»˜è®¤å€¼**: True
- **è¯´æ˜**: æ˜¯å¦å¯ç”¨åŸºäºç”¨æˆ·åé¦ˆçš„å­¦ä¹ åŠŸèƒ½
- **æ³¨æ„**: å½“å‰ç‰ˆæœ¬å­¦ä¹ åŠŸèƒ½ä¸ºåŸºç¡€å®ç°

### ğŸ”§ è‡ªå®šä¹‰æ‰©å±•

#### æ·»åŠ æ–°çš„å†³ç­–å› å­
```python
def _custom_decision_factor(self, question, suggestion):
    """è‡ªå®šä¹‰å†³ç­–å› å­"""
    # å®ç°è‡ªå®šä¹‰é€»è¾‘
    return score_adjustment

# åœ¨_calculate_decision_scoreä¸­æ·»åŠ 
score += self._custom_decision_factor(question, suggestion)
```

#### æ‰©å±•å…³é”®è¯åº“
```python
# åœ¨keyword_patternsä¸­æ·»åŠ æ–°çš„çŸ¥è¯†ç‚¹
self.keyword_patterns["æ–°çŸ¥è¯†ç‚¹"] = [
    "å…³é”®è¯1", "å…³é”®è¯2", "keyword3"
]
```

#### è‡ªå®šä¹‰NLPæ¨¡å‹
```python
class CustomNLPService(NLPService):
    def suggest_knowledge_points(self, question_content, question_type):
        # ä½¿ç”¨è‡ªå®šä¹‰æ¨¡å‹
        predictions = self.custom_model.predict(question_content)
        return self._format_predictions(predictions)
```

### ğŸ“Š æ€§èƒ½ç›‘æ§

#### æ ‡æ³¨è´¨é‡è¯„ä¼°
```python
def evaluate_annotation_quality(self, question_id, user_feedback):
    """è¯„ä¼°AI Agentæ ‡æ³¨è´¨é‡"""
    feedback_annotations = user_feedback.get("annotations", [])
    correct_count = sum(1 for ann in feedback_annotations if ann.get("is_correct"))
    accuracy = correct_count / len(feedback_annotations)
    return {"accuracy": accuracy, "question_id": question_id}
```

#### æ€§èƒ½æŒ‡æ ‡
- **å‡†ç¡®ç‡**: æ­£ç¡®æ ‡æ³¨æ•° / æ€»æ ‡æ³¨æ•°
- **è¦†ç›–ç‡**: è‡ªåŠ¨æ ‡æ³¨é¢˜ç›®æ•° / æ€»é¢˜ç›®æ•°
- **ç½®ä¿¡åº¦åˆ†å¸ƒ**: ä¸åŒç½®ä¿¡åº¦åŒºé—´çš„æ ‡æ³¨åˆ†å¸ƒ
- **å“åº”æ—¶é—´**: å•ä¸ªé¢˜ç›®æ ‡æ³¨è€—æ—¶

## æ•°æ®åº“è®¾è®¡

### ğŸ—„ï¸ Neo4jå›¾æ•°æ®åº“Schema

#### èŠ‚ç‚¹ç±»å‹ (Node Labels)

##### KnowledgePoint (çŸ¥è¯†ç‚¹)
```cypher
CREATE (kp:KnowledgePoint {
    id: "kp_123456",
    name: "ä¸€èˆ¬ç°åœ¨æ—¶",
    description: "è¡¨ç¤ºç»å¸¸æ€§ã€ä¹ æƒ¯æ€§çš„åŠ¨ä½œæˆ–çŠ¶æ€",
    level: "å°å­¦å››å¹´çº§",
    difficulty: "easy",
    keywords: ["always", "usually", "ç¬¬ä¸‰äººç§°å•æ•°"]
})
```

**å±æ€§è¯´æ˜**:
- `id`: å”¯ä¸€æ ‡è¯†ç¬¦
- `name`: çŸ¥è¯†ç‚¹åç§°
- `description`: è¯¦ç»†æè¿°
- `level`: é€‚ç”¨å­¦æ®µ
- `difficulty`: éš¾åº¦ç­‰çº§ (easy/medium/hard)
- `keywords`: å…³é”®è¯æ•°ç»„

##### Question (é¢˜ç›®)
```cypher
CREATE (q:Question {
    id: "q_789012",
    content: "She _____ to school every day.",
    question_type: "é€‰æ‹©é¢˜",
    options: ["go", "goes", "going", "gone"],
    answer: "B",
    analysis: "ä¸»è¯­æ˜¯ç¬¬ä¸‰äººç§°å•æ•°ï¼ŒåŠ¨è¯ç”¨goes",
    source: "äººæ•™ç‰ˆå°å­¦è‹±è¯­",
    difficulty: "easy"
})
```

##### Textbook (æ•™æ)
```cypher
CREATE (t:Textbook {
    id: "tb_001",
    name: "äººæ•™ç‰ˆå°å­¦è‹±è¯­",
    publisher: "äººæ°‘æ•™è‚²å‡ºç‰ˆç¤¾",
    grade: "å°å­¦å››å¹´çº§",
    version: "2021ç‰ˆ"
})
```

##### Chapter (ç« èŠ‚)
```cypher
CREATE (c:Chapter {
    id: "ch_001",
    name: "Unit 1 - My School",
    chapter_number: 1,
    textbook_id: "tb_001",
    description: "ä»‹ç»å­¦æ ¡ç›¸å…³è¯æ±‡å’Œå¥å‹"
})
```

#### å…³ç³»ç±»å‹ (Relationship Types)

##### HAS_SUB_POINT (åŒ…å«å…³ç³»)
```cypher
(parent:KnowledgePoint)-[:HAS_SUB_POINT]->(child:KnowledgePoint)
```
ç”¨äºæ„å»ºçŸ¥è¯†ç‚¹çš„å±‚çº§ç»“æ„ã€‚

##### TESTS (è€ƒæŸ¥å…³ç³»)
```cypher
(q:Question)-[:TESTS {weight: 0.8}]->(kp:KnowledgePoint)
```
è¡¨ç¤ºé¢˜ç›®è€ƒæŸ¥æŸä¸ªçŸ¥è¯†ç‚¹ï¼Œweightè¡¨ç¤ºè€ƒæŸ¥æƒé‡ã€‚

##### BELONGS_TO (å½’å±å…³ç³»)
```cypher
(kp:KnowledgePoint)-[:BELONGS_TO]->(c:Chapter)
(c:Chapter)-[:BELONGS_TO]->(t:Textbook)
```

##### REQUIRES (å‰ç½®è¦æ±‚å…³ç³»)
```cypher
(advanced:KnowledgePoint)-[:REQUIRES {strength: 0.9}]->(basic:KnowledgePoint)
```
è¡¨ç¤ºå­¦ä¹ é«˜çº§çŸ¥è¯†ç‚¹éœ€è¦å…ˆæŒæ¡åŸºç¡€çŸ¥è¯†ç‚¹ã€‚

#### ç´¢å¼•å’Œçº¦æŸ

##### å”¯ä¸€æ€§çº¦æŸ
```cypher
CREATE CONSTRAINT knowledge_point_id IF NOT EXISTS 
FOR (kp:KnowledgePoint) REQUIRE kp.id IS UNIQUE;

CREATE CONSTRAINT question_id IF NOT EXISTS 
FOR (q:Question) REQUIRE q.id IS UNIQUE;
```

##### æ€§èƒ½ç´¢å¼•
```cypher
CREATE INDEX knowledge_point_name IF NOT EXISTS 
FOR (kp:KnowledgePoint) ON (kp.name);

CREATE INDEX question_type IF NOT EXISTS 
FOR (q:Question) ON (q.question_type);

CREATE INDEX question_difficulty IF NOT EXISTS 
FOR (q:Question) ON (q.difficulty);
```

### ğŸ“Š å¸¸ç”¨æŸ¥è¯¢ç¤ºä¾‹

#### æŸ¥æ‰¾çŸ¥è¯†ç‚¹çš„æ‰€æœ‰å­èŠ‚ç‚¹
```cypher
MATCH (parent:KnowledgePoint {name: "åŠ¨è¯æ—¶æ€"})-[:HAS_SUB_POINT*1..3]->(child:KnowledgePoint)
RETURN parent.name, child.name, length(path) as depth
ORDER BY depth, child.name
```

#### æŸ¥æ‰¾è€ƒæŸ¥ç‰¹å®šçŸ¥è¯†ç‚¹çš„é¢˜ç›®
```cypher
MATCH (q:Question)-[r:TESTS]->(kp:KnowledgePoint {name: "ä¸€èˆ¬ç°åœ¨æ—¶"})
RETURN q.content, q.question_type, r.weight
ORDER BY r.weight DESC
```

#### åˆ†æå­¦ç”Ÿè–„å¼±çŸ¥è¯†ç‚¹
```cypher
MATCH (q:Question)-[:TESTS]->(kp:KnowledgePoint)
WHERE q.id IN $wrong_question_ids
RETURN kp.name, count(q) as error_count
ORDER BY error_count DESC
```

#### æ¨èå­¦ä¹ è·¯å¾„
```cypher
MATCH path = (start:KnowledgePoint)-[:REQUIRES*0..3]->(target:KnowledgePoint {name: $target})
WHERE NOT (start)-[:REQUIRES]->()
RETURN [node in nodes(path) | node.name] as learning_path, length(path) as steps
ORDER BY steps
LIMIT 5
```

#### çŸ¥è¯†ç‚¹è¦†ç›–ç‡åˆ†æ
```cypher
MATCH (kp:KnowledgePoint)
OPTIONAL MATCH (q:Question)-[:TESTS]->(kp)
RETURN kp.name, kp.level, count(q) as question_count
ORDER BY question_count DESC
```

## å‰ç«¯å¼€å‘æŒ‡å—

### ğŸ¨ æŠ€æœ¯æ ˆ
- **HTML5**: è¯­ä¹‰åŒ–æ ‡ç­¾
- **CSS3**: Flexbox, Grid, åŠ¨ç”»
- **JavaScript**: ES6+, å¼‚æ­¥ç¼–ç¨‹
- **Bootstrap 5**: å“åº”å¼UIæ¡†æ¶
- **Font Awesome**: å›¾æ ‡åº“

### ğŸ—ï¸ æ¶æ„è®¾è®¡

#### æ–‡ä»¶ç»“æ„
```
frontend/
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ css/
â”‚   â”‚   â””â”€â”€ style.css          # ä¸»æ ·å¼æ–‡ä»¶
â”‚   â””â”€â”€ js/
â”‚       â””â”€â”€ app.js             # ä¸»JavaScriptæ–‡ä»¶
â””â”€â”€ templates/
    â””â”€â”€ index.html             # ä¸»HTMLæ¨¡æ¿
```

#### æ¨¡å—åŒ–è®¾è®¡
```javascript
// app.js æ¨¡å—ç»“æ„
const App = {
    // å…¨å±€å˜é‡
    selectedKnowledgePoints: [],
    currentQuestionId: null,
    
    // åˆå§‹åŒ–
    init() {
        this.loadDashboardStats();
        this.loadKnowledgePoints();
        this.initializeEventListeners();
    },
    
    // çŸ¥è¯†ç‚¹ç®¡ç†
    KnowledgeManager: {
        search: async function(keyword) { /* ... */ },
        create: async function(data) { /* ... */ },
        // ...
    },
    
    // AI Agentäº¤äº’
    AIAgent: {
        autoAnnotate: async function(question) { /* ... */ },
        batchAnnotate: async function(questions) { /* ... */ },
        // ...
    },
    
    // æ•°æ®åˆ†æ
    Analytics: {
        loadStats: async function() { /* ... */ },
        generateReport: async function() { /* ... */ },
        // ...
    }
};
```

### ğŸ“± å“åº”å¼è®¾è®¡

#### æ–­ç‚¹è®¾ç½®
```css
/* ç§»åŠ¨è®¾å¤‡ */
@media (max-width: 768px) {
    .stat-card {
        flex-direction: column;
        text-align: center;
    }
    
    .container {
        padding: 10px;
    }
}

/* å¹³æ¿è®¾å¤‡ */
@media (min-width: 768px) and (max-width: 1024px) {
    .nav-tabs {
        flex-wrap: wrap;
    }
}

/* æ¡Œé¢è®¾å¤‡ */
@media (min-width: 1024px) {
    .sidebar {
        position: fixed;
        height: 100vh;
    }
}
```

#### ç»„ä»¶æ ·å¼
```css
/* ç»Ÿè®¡å¡ç‰‡ */
.stat-card {
    border-radius: 10px;
    padding: 20px;
    display: flex;
    align-items: center;
    box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
    transition: transform 0.2s;
}

.stat-card:hover {
    transform: translateY(-2px);
}

/* çŸ¥è¯†ç‚¹æ ‡ç­¾ */
.knowledge-point-item {
    border: 1px solid #dee2e6;
    border-radius: 6px;
    padding: 12px;
    cursor: pointer;
    transition: all 0.2s;
}

.knowledge-point-item:hover {
    background-color: #f8f9fa;
    border-color: #007bff;
}

/* AIæ¨èæ ·å¼ */
.suggestion-item {
    border: 1px solid #dee2e6;
    border-radius: 6px;
    padding: 12px;
    margin-bottom: 10px;
    cursor: pointer;
}

.suggestion-confidence {
    padding: 2px 8px;
    border-radius: 12px;
    font-size: 0.75rem;
    font-weight: bold;
    color: white;
}

.confidence-high { background-color: #28a745; }
.confidence-medium { background-color: #ffc107; color: #333; }
.confidence-low { background-color: #dc3545; }
```

### ğŸ”„ APIäº¤äº’

#### å¼‚æ­¥è¯·æ±‚å°è£…
```javascript
class ApiClient {
    constructor(baseUrl) {
        this.baseUrl = baseUrl;
    }
    
    async request(method, endpoint, data = null) {
        const url = `${this.baseUrl}${endpoint}`;
        const options = {
            method,
            headers: {
                'Content-Type': 'application/json',
            },
        };
        
        if (data) {
            options.body = JSON.stringify(data);
        }
        
        try {
            const response = await fetch(url, options);
            if (!response.ok) {
                throw new Error(`HTTP ${response.status}: ${response.statusText}`);
            }
            return await response.json();
        } catch (error) {
            console.error(`APIè¯·æ±‚å¤±è´¥: ${method} ${endpoint}`, error);
            throw error;
        }
    }
    
    // ä¾¿æ·æ–¹æ³•
    get(endpoint) { return this.request('GET', endpoint); }
    post(endpoint, data) { return this.request('POST', endpoint, data); }
    put(endpoint, data) { return this.request('PUT', endpoint, data); }
    delete(endpoint) { return this.request('DELETE', endpoint); }
}

// ä½¿ç”¨ç¤ºä¾‹
const api = new ApiClient('/api');

// è·å–çŸ¥è¯†ç‚¹
const knowledgePoints = await api.get('/knowledge/search?keyword=æ—¶æ€');

// åˆ›å»ºé¢˜ç›®
const question = await api.post('/questions/', {
    content: "She goes to school every day.",
    question_type: "é€‰æ‹©é¢˜",
    answer: "goes"
});
```

#### é”™è¯¯å¤„ç†
```javascript
async function handleApiCall(apiFunction, errorMessage) {
    try {
        const result = await apiFunction();
        return { success: true, data: result };
    } catch (error) {
        console.error(errorMessage, error);
        showMessage(errorMessage, 'danger');
        return { success: false, error };
    }
}

// ä½¿ç”¨ç¤ºä¾‹
const result = await handleApiCall(
    () => api.post('/ai-agent/auto-annotate', { question }),
    'AIè‡ªåŠ¨æ ‡æ³¨å¤±è´¥'
);

if (result.success) {
    displayAnnotationResults(result.data);
}
```

### ğŸ­ ç”¨æˆ·äº¤äº’

#### æ¶ˆæ¯æç¤ºç³»ç»Ÿ
```javascript
function showMessage(message, type = 'info', duration = 3000) {
    const alertDiv = document.createElement('div');
    alertDiv.className = `alert alert-${type} alert-dismissible fade show position-fixed`;
    alertDiv.style.cssText = 'top: 20px; right: 20px; z-index: 9999; min-width: 300px;';
    alertDiv.innerHTML = `
        ${message}
        <button type="button" class="btn-close" data-bs-dismiss="alert"></button>
    `;
    
    document.body.appendChild(alertDiv);
    
    setTimeout(() => {
        if (alertDiv.parentNode) {
            alertDiv.parentNode.removeChild(alertDiv);
        }
    }, duration);
}
```

#### åŠ è½½çŠ¶æ€ç®¡ç†
```javascript
function showLoading(containerId, message = 'åŠ è½½ä¸­...') {
    document.getElementById(containerId).innerHTML = `
        <div class="loading">
            <i class="fas fa-spinner fa-spin"></i>
            <p>${message}</p>
        </div>
    `;
}

function hideLoading(containerId, content = '') {
    document.getElementById(containerId).innerHTML = content;
}
```

#### æ¨¡æ€æ¡†ç®¡ç†
```javascript
class ModalManager {
    static show(modalId, options = {}) {
        const modal = new bootstrap.Modal(document.getElementById(modalId), options);
        modal.show();
        return modal;
    }
    
    static hide(modalId) {
        const modal = bootstrap.Modal.getInstance(document.getElementById(modalId));
        if (modal) modal.hide();
    }
    
    static onHide(modalId, callback) {
        document.getElementById(modalId).addEventListener('hidden.bs.modal', callback);
    }
}
```

## æµ‹è¯•æŒ‡å—

### ğŸ§ª æµ‹è¯•ç­–ç•¥

#### æµ‹è¯•é‡‘å­—å¡”
```
    /\     E2Eæµ‹è¯• (å°‘é‡)
   /  \    
  /____\   é›†æˆæµ‹è¯• (é€‚é‡)
 /      \  
/________\ å•å…ƒæµ‹è¯• (å¤§é‡)
```

#### æµ‹è¯•ç±»å‹
1. **å•å…ƒæµ‹è¯•**: æµ‹è¯•å•ä¸ªå‡½æ•°/ç±»
2. **é›†æˆæµ‹è¯•**: æµ‹è¯•æ¨¡å—é—´äº¤äº’
3. **ç³»ç»Ÿæµ‹è¯•**: æµ‹è¯•å®Œæ•´åŠŸèƒ½æµç¨‹
4. **æ€§èƒ½æµ‹è¯•**: æµ‹è¯•å“åº”æ—¶é—´å’Œå¹¶å‘èƒ½åŠ›

### ğŸ”¬ å•å…ƒæµ‹è¯•

#### æµ‹è¯•æ¡†æ¶
```bash
pip install pytest pytest-asyncio pytest-cov
```

#### æµ‹è¯•ç¤ºä¾‹
```python
# test_ai_agent.py
import pytest
from backend.services.ai_agent_service import AIAgentService
from backend.models.schema import Question

@pytest.fixture
def ai_agent():
    return AIAgentService()

@pytest.fixture
def sample_question():
    return Question(
        content="She goes to school every day.",
        question_type="é€‰æ‹©é¢˜",
        answer="goes",
        difficulty="easy"
    )

@pytest.mark.asyncio
async def test_auto_annotate_question(ai_agent, sample_question):
    """æµ‹è¯•å•ä¸ªé¢˜ç›®è‡ªåŠ¨æ ‡æ³¨"""
    result = await ai_agent.auto_annotate_question(sample_question)
    
    assert result["status"] == "completed"
    assert "suggestions" in result
    assert len(result["suggestions"]) > 0

def test_configuration_update(ai_agent):
    """æµ‹è¯•é…ç½®æ›´æ–°"""
    new_config = {
        "confidence_threshold": 0.5,
        "max_auto_annotations": 3
    }
    
    ai_agent.update_configuration(new_config)
    config = ai_agent.get_configuration()
    
    assert config["confidence_threshold"] == 0.5
    assert config["max_auto_annotations"] == 3

@pytest.mark.parametrize("question_type,expected_boost", [
    ("é€‰æ‹©é¢˜", 0.2),
    ("å¡«ç©ºé¢˜", 0.3),
    ("é˜…è¯»ç†è§£", 0.1)
])
def test_question_type_boost(ai_agent, question_type, expected_boost):
    """æµ‹è¯•é¢˜ç›®ç±»å‹åŠ æƒ"""
    boost = ai_agent._get_question_type_boost(question_type, "æ—¶æ€")
    assert boost >= 0
```

#### è¿è¡Œæµ‹è¯•
```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•
pytest

# è¿è¡Œç‰¹å®šæµ‹è¯•æ–‡ä»¶
pytest tests/test_ai_agent.py

# ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š
pytest --cov=backend --cov-report=html

# è¿è¡Œå¼‚æ­¥æµ‹è¯•
pytest -v tests/test_async_functions.py
```

### ğŸ”— é›†æˆæµ‹è¯•

#### æ•°æ®åº“é›†æˆæµ‹è¯•
```python
# test_database_integration.py
import pytest
from backend.services.database import neo4j_service
from backend.models.schema import KnowledgePoint

@pytest.fixture(scope="session")
def db_connection():
    """æ•°æ®åº“è¿æ¥fixture"""
    neo4j_service.connect()
    yield neo4j_service
    neo4j_service.close()

def test_create_and_retrieve_knowledge_point(db_connection):
    """æµ‹è¯•çŸ¥è¯†ç‚¹åˆ›å»ºå’Œæ£€ç´¢"""
    kp = KnowledgePoint(
        name="æµ‹è¯•çŸ¥è¯†ç‚¹",
        description="è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•çŸ¥è¯†ç‚¹",
        level="å°å­¦ä¸€å¹´çº§",
        difficulty="easy"
    )
    
    # åˆ›å»ºçŸ¥è¯†ç‚¹
    kp_id = db_connection.create_knowledge_point(kp)
    assert kp_id is not None
    
    # æ£€ç´¢çŸ¥è¯†ç‚¹
    retrieved_kp = db_connection.get_knowledge_point(kp_id)
    assert retrieved_kp["name"] == "æµ‹è¯•çŸ¥è¯†ç‚¹"
    
    # æ¸…ç†æµ‹è¯•æ•°æ®
    with db_connection.driver.session() as session:
        session.run("MATCH (kp:KnowledgePoint {id: $id}) DELETE kp", {"id": kp_id})
```

#### APIé›†æˆæµ‹è¯•
```python
# test_api_integration.py
import pytest
from fastapi.testclient import TestClient
from backend.api.main import app

@pytest.fixture
def client():
    return TestClient(app)

def test_create_knowledge_point_api(client):
    """æµ‹è¯•çŸ¥è¯†ç‚¹åˆ›å»ºAPI"""
    kp_data = {
        "name": "APIæµ‹è¯•çŸ¥è¯†ç‚¹",
        "description": "é€šè¿‡APIåˆ›å»ºçš„æµ‹è¯•çŸ¥è¯†ç‚¹",
        "level": "å°å­¦äºŒå¹´çº§",
        "difficulty": "medium"
    }
    
    response = client.post("/api/knowledge/", json=kp_data)
    assert response.status_code == 200
    
    result = response.json()
    assert "id" in result
    assert result["message"] == "çŸ¥è¯†ç‚¹åˆ›å»ºæˆåŠŸ"

def test_ai_agent_auto_annotate_api(client):
    """æµ‹è¯•AI Agentè‡ªåŠ¨æ ‡æ³¨API"""
    question_data = {
        "question": {
            "content": "She plays tennis every weekend.",
            "question_type": "é€‰æ‹©é¢˜",
            "answer": "plays"
        }
    }
    
    response = client.post("/api/ai-agent/auto-annotate", json=question_data)
    assert response.status_code == 200
    
    result = response.json()
    assert result["status"] == "completed"
    assert "suggestions" in result
```

### ğŸ­ ç«¯åˆ°ç«¯æµ‹è¯•

#### Seleniumæµ‹è¯•
```python
# test_e2e.py
import pytest
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

@pytest.fixture
def driver():
    driver = webdriver.Chrome()  # éœ€è¦å®‰è£…ChromeDriver
    driver.get("http://localhost:8000")
    yield driver
    driver.quit()

def test_knowledge_point_creation_flow(driver):
    """æµ‹è¯•çŸ¥è¯†ç‚¹åˆ›å»ºæµç¨‹"""
    # ç‚¹å‡»æ·»åŠ çŸ¥è¯†ç‚¹æŒ‰é’®
    add_btn = WebDriverWait(driver, 10).until(
        EC.element_to_be_clickable((By.XPATH, "//button[contains(text(), 'æ·»åŠ ')]"))
    )
    add_btn.click()
    
    # å¡«å†™è¡¨å•
    name_input = driver.find_element(By.ID, "new-kp-name")
    name_input.send_keys("E2Eæµ‹è¯•çŸ¥è¯†ç‚¹")
    
    description_input = driver.find_element(By.ID, "new-kp-description")
    description_input.send_keys("è¿™æ˜¯é€šè¿‡E2Eæµ‹è¯•åˆ›å»ºçš„çŸ¥è¯†ç‚¹")
    
    # æäº¤è¡¨å•
    submit_btn = driver.find_element(By.XPATH, "//button[contains(text(), 'æ·»åŠ ')]")
    submit_btn.click()
    
    # éªŒè¯æˆåŠŸæ¶ˆæ¯
    success_message = WebDriverWait(driver, 10).until(
        EC.presence_of_element_located((By.CLASS_NAME, "alert-success"))
    )
    assert "çŸ¥è¯†ç‚¹æ·»åŠ æˆåŠŸ" in success_message.text

def test_ai_annotation_flow(driver):
    """æµ‹è¯•AIè‡ªåŠ¨æ ‡æ³¨æµç¨‹"""
    # åˆ‡æ¢åˆ°æ ‡æ³¨æ ‡ç­¾é¡µ
    annotation_tab = driver.find_element(By.ID, "annotation-tab")
    annotation_tab.click()
    
    # è¾“å…¥é¢˜ç›®å†…å®¹
    content_textarea = driver.find_element(By.ID, "question-content")
    content_textarea.send_keys("Tom plays basketball every day.")
    
    # è¾“å…¥ç­”æ¡ˆ
    answer_input = driver.find_element(By.ID, "question-answer")
    answer_input.send_keys("plays")
    
    # ç‚¹å‡»AIæ™ºèƒ½æ¨è
    ai_btn = driver.find_element(By.XPATH, "//button[contains(text(), 'AIæ™ºèƒ½æ¨è')]")
    ai_btn.click()
    
    # ç­‰å¾…æ¨èç»“æœ
    suggestions = WebDriverWait(driver, 10).until(
        EC.presence_of_element_located((By.ID, "knowledge-suggestions"))
    )
    
    # éªŒè¯æœ‰æ¨èç»“æœ
    suggestion_items = driver.find_elements(By.CLASS_NAME, "suggestion-item")
    assert len(suggestion_items) > 0
```

### âš¡ æ€§èƒ½æµ‹è¯•

#### è´Ÿè½½æµ‹è¯•
```python
# test_performance.py
import asyncio
import time
import aiohttp
from concurrent.futures import ThreadPoolExecutor

async def test_api_performance():
    """æµ‹è¯•APIæ€§èƒ½"""
    async def make_request(session, url):
        start_time = time.time()
        async with session.get(url) as response:
            await response.json()
            return time.time() - start_time
    
    url = "http://localhost:8000/api/knowledge/search?keyword=æ—¶æ€"
    
    async with aiohttp.ClientSession() as session:
        # å¹¶å‘100ä¸ªè¯·æ±‚
        tasks = [make_request(session, url) for _ in range(100)]
        response_times = await asyncio.gather(*tasks)
    
    # åˆ†æç»“æœ
    avg_time = sum(response_times) / len(response_times)
    max_time = max(response_times)
    min_time = min(response_times)
    
    print(f"å¹³å‡å“åº”æ—¶é—´: {avg_time:.3f}s")
    print(f"æœ€å¤§å“åº”æ—¶é—´: {max_time:.3f}s")
    print(f"æœ€å°å“åº”æ—¶é—´: {min_time:.3f}s")
    
    # æ–­è¨€æ€§èƒ½è¦æ±‚
    assert avg_time < 1.0  # å¹³å‡å“åº”æ—¶é—´å°äº1ç§’
    assert max_time < 5.0  # æœ€å¤§å“åº”æ—¶é—´å°äº5ç§’

if __name__ == "__main__":
    asyncio.run(test_api_performance())
```

#### AI Agentæ€§èƒ½æµ‹è¯•
```python
async def test_ai_agent_batch_performance():
    """æµ‹è¯•AI Agentæ‰¹é‡å¤„ç†æ€§èƒ½"""
    from backend.services.ai_agent_service import ai_agent_service
    from backend.models.schema import Question
    
    # åˆ›å»ºæµ‹è¯•é¢˜ç›®
    questions = [
        Question(
            content=f"Test question {i}",
            question_type="é€‰æ‹©é¢˜",
            answer=f"answer_{i}"
        ) for i in range(100)
    ]
    
    # æµ‹è¯•æ‰¹é‡æ ‡æ³¨æ€§èƒ½
    start_time = time.time()
    result = await ai_agent_service.batch_auto_annotate(questions)
    end_time = time.time()
    
    processing_time = end_time - start_time
    throughput = len(questions) / processing_time
    
    print(f"æ‰¹é‡å¤„ç†æ—¶é—´: {processing_time:.3f}s")
    print(f"å¤„ç†ååé‡: {throughput:.1f} questions/second")
    
    # æ€§èƒ½æ–­è¨€
    assert throughput > 10  # æ¯ç§’è‡³å°‘å¤„ç†10é“é¢˜ç›®
    assert result["success_rate"] > 0.8  # æˆåŠŸç‡å¤§äº80%
```

### ğŸ“Š æµ‹è¯•æŠ¥å‘Š

#### ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
```bash
# ç”ŸæˆHTMLæµ‹è¯•æŠ¥å‘Š
pytest --html=reports/test_report.html --self-contained-html

# ç”ŸæˆJUnitæ ¼å¼æŠ¥å‘Š
pytest --junitxml=reports/junit.xml

# ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š
pytest --cov=backend --cov-report=html:reports/coverage
```

#### CI/CDé›†æˆ
```yaml
# .github/workflows/test.yml
name: Test Suite

on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    
    services:
      neo4j:
        image: neo4j:latest
        env:
          NEO4J_AUTH: neo4j/test
        ports:
          - 7687:7687
          - 7474:7474
    
    steps:
    - uses: actions/checkout@v2
    
    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: 3.8
    
    - name: Install dependencies
      run: |
        pip install -r requirements.txt
        pip install pytest pytest-cov
    
    - name: Run tests
      run: |
        pytest --cov=backend --cov-report=xml
    
    - name: Upload coverage
      uses: codecov/codecov-action@v1
```

## éƒ¨ç½²æŒ‡å—

### ğŸš€ æœ¬åœ°å¼€å‘éƒ¨ç½²

#### å¿«é€Ÿå¯åŠ¨
```bash
# 1. å¯åŠ¨Neo4j
brew services start neo4j

# 2. æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
source venv/bin/activate

# 3. å¯åŠ¨åº”ç”¨
python run.py
```

#### å¼€å‘æ¨¡å¼é…ç½®
```python
# config.env
DEBUG=True
APP_HOST=0.0.0.0
APP_PORT=8000
NEO4J_URI=bolt://localhost:7687
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=your_password
```

### ğŸ³ Dockeréƒ¨ç½²

#### Dockerfile
```dockerfile
# Dockerfile
FROM python:3.9-slim

WORKDIR /app

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    && rm -rf /var/lib/apt/lists/*

# å¤åˆ¶ä¾èµ–æ–‡ä»¶
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# å¤åˆ¶åº”ç”¨ä»£ç 
COPY . .

# æš´éœ²ç«¯å£
EXPOSE 8000

# å¯åŠ¨å‘½ä»¤
CMD ["python", "run.py"]
```

#### Docker Compose
```yaml
# docker-compose.yml
version: '3.8'

services:
  neo4j:
    image: neo4j:latest
    environment:
      NEO4J_AUTH: neo4j/knowledge123
      NEO4J_PLUGINS: '["apoc"]'
    ports:
      - "7474:7474"
      - "7687:7687"
    volumes:
      - neo4j_data:/data
      - neo4j_logs:/logs

  app:
    build: .
    ports:
      - "8000:8000"
    environment:
      NEO4J_URI: bolt://neo4j:7687
      NEO4J_USERNAME: neo4j
      NEO4J_PASSWORD: knowledge123
    depends_on:
      - neo4j
    volumes:
      - ./logs:/app/logs

volumes:
  neo4j_data:
  neo4j_logs:
```

#### æ„å»ºå’Œè¿è¡Œ
```bash
# æ„å»ºé•œåƒ
docker-compose build

# å¯åŠ¨æœåŠ¡
docker-compose up -d

# æŸ¥çœ‹æ—¥å¿—
docker-compose logs -f app

# åœæ­¢æœåŠ¡
docker-compose down
```

### â˜ï¸ äº‘æœåŠ¡å™¨éƒ¨ç½²

#### ç³»ç»Ÿè¦æ±‚
- **æ“ä½œç³»ç»Ÿ**: Ubuntu 20.04 LTS æˆ– CentOS 8+
- **å†…å­˜**: 4GB+ (æ¨è8GB+)
- **CPU**: 2æ ¸å¿ƒ+ (æ¨è4æ ¸å¿ƒ+)
- **å­˜å‚¨**: 50GB+ SSD
- **ç½‘ç»œ**: ç¨³å®šçš„äº’è”ç½‘è¿æ¥

#### éƒ¨ç½²æ­¥éª¤
```bash
# 1. æ›´æ–°ç³»ç»Ÿ
sudo apt update && sudo apt upgrade -y

# 2. å®‰è£…Python 3.8+
sudo apt install python3.8 python3.8-pip python3.8-venv -y

# 3. å®‰è£…Neo4j
wget -O - https://debian.neo4j.com/neotechnology.gpg.key | sudo apt-key add -
echo 'deb https://debian.neo4j.com stable latest' | sudo tee /etc/apt/sources.list.d/neo4j.list
sudo apt update
sudo apt install neo4j -y

# 4. é…ç½®Neo4j
sudo systemctl enable neo4j
sudo systemctl start neo4j

# 5. å…‹éš†é¡¹ç›®
git clone <repository-url>
cd è‹±è¯­çŸ¥è¯†å›¾åº“

# 6. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python3.8 -m venv venv
source venv/bin/activate

# 7. å®‰è£…ä¾èµ–
pip install -r requirements.txt

# 8. é…ç½®ç¯å¢ƒ
cp config.env.example config.env
# ç¼–è¾‘config.env

# 9. åˆå§‹åŒ–æ•°æ®åº“
python scripts/init_database.py
python scripts/load_sample_data.py

# 10. ä½¿ç”¨Gunicornéƒ¨ç½²
pip install gunicorn
gunicorn -w 4 -k uvicorn.workers.UvicornWorker backend.api.main:app --bind 0.0.0.0:8000
```

#### Nginxåå‘ä»£ç†
```nginx
# /etc/nginx/sites-available/knowledge-graph
server {
    listen 80;
    server_name your-domain.com;
    
    location / {
        proxy_pass http://127.0.0.1:8000;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }
    
    location /static/ {
        alias /path/to/your/project/frontend/static/;
        expires 1y;
        add_header Cache-Control "public, immutable";
    }
}
```

#### ç³»ç»ŸæœåŠ¡é…ç½®
```ini
# /etc/systemd/system/knowledge-graph.service
[Unit]
Description=K12 English Knowledge Graph System
After=network.target neo4j.service

[Service]
Type=exec
User=www-data
Group=www-data
WorkingDirectory=/path/to/your/project
Environment=PATH=/path/to/your/project/venv/bin
ExecStart=/path/to/your/project/venv/bin/gunicorn -w 4 -k uvicorn.workers.UvicornWorker backend.api.main:app --bind 127.0.0.1:8000
Restart=always
RestartSec=10

[Install]
WantedBy=multi-user.target
```

```bash
# å¯ç”¨æœåŠ¡
sudo systemctl enable knowledge-graph
sudo systemctl start knowledge-graph
sudo systemctl status knowledge-graph
```

### ğŸ“Š ç›‘æ§å’Œæ—¥å¿—

#### åº”ç”¨ç›‘æ§
```python
# backend/utils/monitoring.py
import time
import logging
from functools import wraps
from typing import Dict, Any

logger = logging.getLogger(__name__)

def monitor_performance(func):
    """æ€§èƒ½ç›‘æ§è£…é¥°å™¨"""
    @wraps(func)
    async def wrapper(*args, **kwargs):
        start_time = time.time()
        try:
            result = await func(*args, **kwargs)
            execution_time = time.time() - start_time
            logger.info(f"{func.__name__} æ‰§è¡Œæ—¶é—´: {execution_time:.3f}s")
            return result
        except Exception as e:
            execution_time = time.time() - start_time
            logger.error(f"{func.__name__} æ‰§è¡Œå¤±è´¥ ({execution_time:.3f}s): {e}")
            raise
    return wrapper

def log_api_access(request, response, execution_time):
    """APIè®¿é—®æ—¥å¿—"""
    logger.info(f"APIè®¿é—®: {request.method} {request.url.path} - "
               f"çŠ¶æ€ç : {response.status_code} - "
               f"è€—æ—¶: {execution_time:.3f}s")
```

#### æ—¥å¿—é…ç½®
```python
# backend/utils/logging_config.py
import logging
import logging.handlers
from pathlib import Path

def setup_logging():
    """é…ç½®æ—¥å¿—ç³»ç»Ÿ"""
    # åˆ›å»ºæ—¥å¿—ç›®å½•
    log_dir = Path("logs")
    log_dir.mkdir(exist_ok=True)
    
    # é…ç½®æ ¹æ—¥å¿—å™¨
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            # æ§åˆ¶å°è¾“å‡º
            logging.StreamHandler(),
            # æ–‡ä»¶è¾“å‡ºï¼ˆè‡ªåŠ¨è½®è½¬ï¼‰
            logging.handlers.RotatingFileHandler(
                log_dir / "app.log",
                maxBytes=10*1024*1024,  # 10MB
                backupCount=5
            )
        ]
    )
    
    # é…ç½®ç‰¹å®šæ¨¡å—æ—¥å¿—çº§åˆ«
    logging.getLogger("uvicorn").setLevel(logging.WARNING)
    logging.getLogger("neo4j").setLevel(logging.WARNING)
```

#### å¥åº·æ£€æŸ¥
```python
# backend/api/health.py
from fastapi import APIRouter
from backend.services.database import neo4j_service

router = APIRouter()

@router.get("/health")
async def health_check():
    """ç³»ç»Ÿå¥åº·æ£€æŸ¥"""
    health_status = {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "services": {}
    }
    
    # æ£€æŸ¥æ•°æ®åº“è¿æ¥
    try:
        if neo4j_service.driver:
            with neo4j_service.driver.session() as session:
                result = session.run("RETURN 1")
                result.single()
            health_status["services"]["neo4j"] = "healthy"
        else:
            health_status["services"]["neo4j"] = "disconnected"
            health_status["status"] = "degraded"
    except Exception as e:
        health_status["services"]["neo4j"] = f"error: {str(e)}"
        health_status["status"] = "unhealthy"
    
    return health_status

@router.get("/metrics")
async def get_metrics():
    """ç³»ç»ŸæŒ‡æ ‡"""
    # è¿™é‡Œå¯ä»¥é›†æˆPrometheusç­‰ç›‘æ§ç³»ç»Ÿ
    return {
        "requests_total": 0,
        "response_time_avg": 0.0,
        "active_connections": 0
    }
```

## æ€§èƒ½ä¼˜åŒ–

### âš¡ æ•°æ®åº“ä¼˜åŒ–

#### æŸ¥è¯¢ä¼˜åŒ–
```cypher
-- åˆ›å»ºå¤åˆç´¢å¼•
CREATE INDEX question_type_difficulty IF NOT EXISTS 
FOR (q:Question) ON (q.question_type, q.difficulty);

-- ä¼˜åŒ–çŸ¥è¯†ç‚¹æœç´¢æŸ¥è¯¢
MATCH (kp:KnowledgePoint)
WHERE kp.name CONTAINS $keyword 
   OR any(k in kp.keywords WHERE k CONTAINS $keyword)
RETURN kp
ORDER BY kp.name
LIMIT 50;  -- é™åˆ¶ç»“æœæ•°é‡

-- ä½¿ç”¨EXPLAINåˆ†ææŸ¥è¯¢è®¡åˆ’
EXPLAIN MATCH (q:Question)-[:TESTS]->(kp:KnowledgePoint {name: $name})
RETURN q.content, q.difficulty;
```

#### è¿æ¥æ± é…ç½®
```python
# backend/services/database.py
from neo4j import GraphDatabase

class Neo4jService:
    def __init__(self):
        self.driver = None
    
    def connect(self):
        self.driver = GraphDatabase.driver(
            self.uri,
            auth=(self.username, self.password),
            # è¿æ¥æ± é…ç½®
            max_connection_lifetime=3600,  # 1å°æ—¶
            max_connection_pool_size=50,   # æœ€å¤§è¿æ¥æ•°
            connection_acquisition_timeout=60  # è·å–è¿æ¥è¶…æ—¶
        )
```

#### æ‰¹é‡æ“ä½œä¼˜åŒ–
```python
def batch_create_questions(self, questions: List[Question], batch_size: int = 100):
    """æ‰¹é‡åˆ›å»ºé¢˜ç›®"""
    with self.driver.session() as session:
        for i in range(0, len(questions), batch_size):
            batch = questions[i:i + batch_size]
            
            # ä½¿ç”¨UNWINDæ‰¹é‡æ’å…¥
            cypher = """
            UNWIND $questions as q
            CREATE (question:Question {
                id: q.id,
                content: q.content,
                question_type: q.question_type,
                answer: q.answer,
                difficulty: q.difficulty
            })
            """
            
            question_data = [q.dict() for q in batch]
            session.run(cypher, {"questions": question_data})
```

### ğŸ§  AI Agentä¼˜åŒ–

#### ç¼“å­˜æœºåˆ¶
```python
from functools import lru_cache
import redis

class AIAgentService:
    def __init__(self):
        self.redis_client = redis.Redis(host='localhost', port=6379, db=0)
    
    @lru_cache(maxsize=1000)
    def _get_cached_suggestions(self, question_hash: str):
        """ç¼“å­˜çŸ¥è¯†ç‚¹å»ºè®®"""
        cache_key = f"suggestions:{question_hash}"
        cached_result = self.redis_client.get(cache_key)
        
        if cached_result:
            return json.loads(cached_result)
        return None
    
    def _cache_suggestions(self, question_hash: str, suggestions: List[Dict]):
        """ç¼“å­˜å»ºè®®ç»“æœ"""
        cache_key = f"suggestions:{question_hash}"
        self.redis_client.setex(
            cache_key, 
            3600,  # 1å°æ—¶è¿‡æœŸ
            json.dumps(suggestions, ensure_ascii=False)
        )
```

#### å¼‚æ­¥å¤„ç†ä¼˜åŒ–
```python
import asyncio
from concurrent.futures import ThreadPoolExecutor

class AIAgentService:
    def __init__(self):
        self.executor = ThreadPoolExecutor(max_workers=4)
    
    async def batch_auto_annotate_optimized(self, questions: List[Question]):
        """ä¼˜åŒ–çš„æ‰¹é‡æ ‡æ³¨"""
        # å°†é¢˜ç›®åˆ†ç»„
        batches = [questions[i:i+10] for i in range(0, len(questions), 10)]
        
        # å¹¶è¡Œå¤„ç†æ¯ä¸ªæ‰¹æ¬¡
        tasks = [
            self._process_batch_async(batch) 
            for batch in batches
        ]
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # åˆå¹¶ç»“æœ
        all_results = []
        for result in results:
            if isinstance(result, list):
                all_results.extend(result)
        
        return all_results
    
    async def _process_batch_async(self, batch: List[Question]):
        """å¼‚æ­¥å¤„ç†æ‰¹æ¬¡"""
        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(
            self.executor,
            self._process_batch_sync,
            batch
        )
```

### ğŸŒ APIæ€§èƒ½ä¼˜åŒ–

#### å“åº”ç¼“å­˜
```python
from fastapi import FastAPI
from fastapi_cache import FastAPICache
from fastapi_cache.backends.redis import RedisBackend
from fastapi_cache.decorator import cache

app = FastAPI()

@app.on_event("startup")
async def startup():
    redis = aioredis.from_url("redis://localhost")
    FastAPICache.init(RedisBackend(redis), prefix="api-cache")

@router.get("/knowledge/search")
@cache(expire=300)  # ç¼“å­˜5åˆ†é’Ÿ
async def search_knowledge_points(keyword: str):
    return neo4j_service.search_knowledge_points(keyword)
```

#### åˆ†é¡µä¼˜åŒ–
```python
from fastapi import Query
from typing import Optional

@router.get("/questions/")
async def get_questions(
    page: int = Query(1, ge=1),
    size: int = Query(20, ge=1, le=100),
    difficulty: Optional[str] = None,
    question_type: Optional[str] = None
):
    """åˆ†é¡µè·å–é¢˜ç›®"""
    offset = (page - 1) * size
    
    # æ„å»ºæŸ¥è¯¢æ¡ä»¶
    conditions = []
    params = {"offset": offset, "limit": size}
    
    if difficulty:
        conditions.append("q.difficulty = $difficulty")
        params["difficulty"] = difficulty
    
    if question_type:
        conditions.append("q.question_type = $question_type")
        params["question_type"] = question_type
    
    where_clause = "WHERE " + " AND ".join(conditions) if conditions else ""
    
    cypher = f"""
    MATCH (q:Question)
    {where_clause}
    RETURN q
    ORDER BY q.id
    SKIP $offset
    LIMIT $limit
    """
    
    with neo4j_service.driver.session() as session:
        result = session.run(cypher, params)
        questions = [dict(record["q"]) for record in result]
    
    return {
        "questions": questions,
        "page": page,
        "size": size,
        "total": len(questions)  # å®é™…åº”ç”¨ä¸­éœ€è¦å•ç‹¬æŸ¥è¯¢æ€»æ•°
    }
```

#### å‹ç¼©å’ŒCDN
```python
from fastapi.middleware.gzip import GZipMiddleware
from fastapi.staticfiles import StaticFiles

# å¯ç”¨GZIPå‹ç¼©
app.add_middleware(GZipMiddleware, minimum_size=1000)

# é™æ€æ–‡ä»¶é…ç½®ï¼ˆç”Ÿäº§ç¯å¢ƒå»ºè®®ä½¿ç”¨CDNï¼‰
app.mount("/static", StaticFiles(directory="frontend/static"), name="static")
```

### ğŸ¨ å‰ç«¯æ€§èƒ½ä¼˜åŒ–

#### ä»£ç åˆ†å‰²å’Œæ‡’åŠ è½½
```javascript
// åŠ¨æ€å¯¼å…¥æ¨¡å—
async function loadAnalyticsModule() {
    const { AnalyticsManager } = await import('./analytics.js');
    return new AnalyticsManager();
}

// å›¾ç‰‡æ‡’åŠ è½½
class LazyLoader {
    static observe() {
        const images = document.querySelectorAll('img[data-src]');
        const imageObserver = new IntersectionObserver((entries) => {
            entries.forEach(entry => {
                if (entry.isIntersecting) {
                    const img = entry.target;
                    img.src = img.dataset.src;
                    img.removeAttribute('data-src');
                    imageObserver.unobserve(img);
                }
            });
        });
        
        images.forEach(img => imageObserver.observe(img));
    }
}
```

#### è¯·æ±‚ä¼˜åŒ–
```javascript
class RequestOptimizer {
    constructor() {
        this.requestCache = new Map();
        this.pendingRequests = new Map();
    }
    
    async optimizedRequest(url, options = {}) {
        // è¯·æ±‚å»é‡
        if (this.pendingRequests.has(url)) {
            return this.pendingRequests.get(url);
        }
        
        // ç¼“å­˜æ£€æŸ¥
        const cacheKey = `${url}:${JSON.stringify(options)}`;
        if (this.requestCache.has(cacheKey)) {
            const cached = this.requestCache.get(cacheKey);
            if (Date.now() - cached.timestamp < 300000) { // 5åˆ†é’Ÿç¼“å­˜
                return cached.data;
            }
        }
        
        // å‘èµ·è¯·æ±‚
        const requestPromise = fetch(url, options)
            .then(response => response.json())
            .then(data => {
                // ç¼“å­˜ç»“æœ
                this.requestCache.set(cacheKey, {
                    data,
                    timestamp: Date.now()
                });
                
                // æ¸…ç†pending
                this.pendingRequests.delete(url);
                
                return data;
            })
            .catch(error => {
                this.pendingRequests.delete(url);
                throw error;
            });
        
        this.pendingRequests.set(url, requestPromise);
        return requestPromise;
    }
}
```

#### è™šæ‹Ÿæ»šåŠ¨
```javascript
class VirtualScroller {
    constructor(container, itemHeight, renderItem) {
        this.container = container;
        this.itemHeight = itemHeight;
        this.renderItem = renderItem;
        this.data = [];
        this.visibleStart = 0;
        this.visibleEnd = 0;
        
        this.setupScrollListener();
    }
    
    setData(data) {
        this.data = data;
        this.updateVisibleRange();
        this.render();
    }
    
    updateVisibleRange() {
        const scrollTop = this.container.scrollTop;
        const containerHeight = this.container.clientHeight;
        
        this.visibleStart = Math.floor(scrollTop / this.itemHeight);
        this.visibleEnd = Math.min(
            this.visibleStart + Math.ceil(containerHeight / this.itemHeight) + 1,
            this.data.length
        );
    }
    
    render() {
        const fragment = document.createDocumentFragment();
        
        for (let i = this.visibleStart; i < this.visibleEnd; i++) {
            const item = this.renderItem(this.data[i], i);
            item.style.position = 'absolute';
            item.style.top = `${i * this.itemHeight}px`;
            fragment.appendChild(item);
        }
        
        this.container.innerHTML = '';
        this.container.appendChild(fragment);
        this.container.style.height = `${this.data.length * this.itemHeight}px`;
    }
    
    setupScrollListener() {
        this.container.addEventListener('scroll', () => {
            this.updateVisibleRange();
            this.render();
        });
    }
}
```

## æ•…éšœæ’æŸ¥

### ğŸ” å¸¸è§é—®é¢˜è¯Šæ–­

#### æ•°æ®åº“è¿æ¥é—®é¢˜
```python
def diagnose_database_connection():
    """è¯Šæ–­æ•°æ®åº“è¿æ¥é—®é¢˜"""
    issues = []
    
    # æ£€æŸ¥Neo4jæœåŠ¡çŠ¶æ€
    try:
        import subprocess
        result = subprocess.run(['neo4j', 'status'], capture_output=True, text=True)
        if 'running' not in result.stdout.lower():
            issues.append("Neo4jæœåŠ¡æœªè¿è¡Œ")
    except FileNotFoundError:
        issues.append("Neo4jæœªå®‰è£…æˆ–ä¸åœ¨PATHä¸­")
    
    # æ£€æŸ¥ç«¯å£è¿æ¥
    import socket
    try:
        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        sock.settimeout(5)
        result = sock.connect_ex(('localhost', 7687))
        if result != 0:
            issues.append("æ— æ³•è¿æ¥åˆ°Neo4jç«¯å£7687")
        sock.close()
    except Exception as e:
        issues.append(f"ç«¯å£æ£€æŸ¥å¤±è´¥: {e}")
    
    # æ£€æŸ¥è®¤è¯ä¿¡æ¯
    try:
        from neo4j import GraphDatabase
        driver = GraphDatabase.driver(
            "bolt://localhost:7687",
            auth=("neo4j", "wrong_password")
        )
        with driver.session() as session:
            session.run("RETURN 1")
    except Exception as e:
        if "unauthorized" in str(e).lower():
            issues.append("æ•°æ®åº“è®¤è¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç”¨æˆ·åå¯†ç ")
    
    return issues
```

#### AI Agentæ€§èƒ½é—®é¢˜
```python
def diagnose_ai_agent_performance():
    """è¯Šæ–­AI Agentæ€§èƒ½é—®é¢˜"""
    import time
    import psutil
    
    diagnostics = {
        "memory_usage": psutil.virtual_memory().percent,
        "cpu_usage": psutil.cpu_percent(interval=1),
        "disk_usage": psutil.disk_usage('/').percent
    }
    
    # æµ‹è¯•NLPå¤„ç†é€Ÿåº¦
    start_time = time.time()
    suggestions = nlp_service.suggest_knowledge_points(
        "This is a test question", "é€‰æ‹©é¢˜"
    )
    nlp_time = time.time() - start_time
    
    diagnostics["nlp_processing_time"] = nlp_time
    diagnostics["suggestions_count"] = len(suggestions)
    
    # æ£€æŸ¥çŸ¥è¯†ç‚¹æ•°é‡
    kp_count = len(neo4j_service.search_knowledge_points(""))
    diagnostics["knowledge_points_count"] = kp_count
    
    # æ€§èƒ½å»ºè®®
    recommendations = []
    if diagnostics["memory_usage"] > 80:
        recommendations.append("å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜ï¼Œè€ƒè™‘å¢åŠ å†…å­˜æˆ–ä¼˜åŒ–ç¼“å­˜")
    if diagnostics["nlp_processing_time"] > 2.0:
        recommendations.append("NLPå¤„ç†é€Ÿåº¦è¾ƒæ…¢ï¼Œè€ƒè™‘ä¼˜åŒ–ç®—æ³•æˆ–å¢åŠ ç¼“å­˜")
    if diagnostics["knowledge_points_count"] < 10:
        recommendations.append("çŸ¥è¯†ç‚¹æ•°é‡è¿‡å°‘ï¼Œå¯èƒ½å½±å“æ¨èè´¨é‡")
    
    diagnostics["recommendations"] = recommendations
    return diagnostics
```

### ğŸš¨ é”™è¯¯å¤„ç†å’Œæ¢å¤

#### è‡ªåŠ¨é‡è¯•æœºåˆ¶
```python
import functools
import time
import random

def retry_with_backoff(max_retries=3, base_delay=1, max_delay=60):
    """å¸¦é€€é¿çš„é‡è¯•è£…é¥°å™¨"""
    def decorator(func):
        @functools.wraps(func)
        async def wrapper(*args, **kwargs):
            last_exception = None
            
            for attempt in range(max_retries + 1):
                try:
                    return await func(*args, **kwargs)
                except Exception as e:
                    last_exception = e
                    
                    if attempt == max_retries:
                        break
                    
                    # è®¡ç®—é€€é¿å»¶è¿Ÿ
                    delay = min(base_delay * (2 ** attempt) + random.uniform(0, 1), max_delay)
                    logger.warning(f"{func.__name__} ç¬¬{attempt + 1}æ¬¡å°è¯•å¤±è´¥ï¼Œ{delay:.1f}ç§’åé‡è¯•: {e}")
                    
                    await asyncio.sleep(delay)
            
            logger.error(f"{func.__name__} é‡è¯•{max_retries}æ¬¡åä»ç„¶å¤±è´¥")
            raise last_exception
        
        return wrapper
    return decorator

# ä½¿ç”¨ç¤ºä¾‹
@retry_with_backoff(max_retries=3)
async def create_question_with_retry(question):
    return neo4j_service.create_question(question)
```

#### æ•°æ®åº“è¿æ¥æ¢å¤
```python
class ResilientNeo4jService(Neo4jService):
    def __init__(self):
        super().__init__()
        self.connection_healthy = False
        self.last_health_check = 0
    
    def _check_connection_health(self):
        """æ£€æŸ¥è¿æ¥å¥åº·çŠ¶æ€"""
        now = time.time()
        if now - self.last_health_check < 30:  # 30ç§’å†…ä¸é‡å¤æ£€æŸ¥
            return self.connection_healthy
        
        try:
            with self.driver.session() as session:
                session.run("RETURN 1").single()
            self.connection_healthy = True
        except Exception as e:
            logger.warning(f"æ•°æ®åº“è¿æ¥ä¸å¥åº·: {e}")
            self.connection_healthy = False
        
        self.last_health_check = now
        return self.connection_healthy
    
    def _reconnect_if_needed(self):
        """å¿…è¦æ—¶é‡æ–°è¿æ¥"""
        if not self._check_connection_health():
            logger.info("å°è¯•é‡æ–°è¿æ¥æ•°æ®åº“...")
            try:
                if self.driver:
                    self.driver.close()
                self.connect()
                logger.info("æ•°æ®åº“é‡è¿æˆåŠŸ")
            except Exception as e:
                logger.error(f"æ•°æ®åº“é‡è¿å¤±è´¥: {e}")
                raise
    
    def execute_with_retry(self, operation):
        """å¸¦é‡è¯•çš„æ•°æ®åº“æ“ä½œ"""
        max_retries = 3
        
        for attempt in range(max_retries):
            try:
                self._reconnect_if_needed()
                return operation()
            except Exception as e:
                if attempt == max_retries - 1:
                    raise
                logger.warning(f"æ•°æ®åº“æ“ä½œå¤±è´¥ï¼Œç¬¬{attempt + 1}æ¬¡é‡è¯•: {e}")
                time.sleep(2 ** attempt)
```

### ğŸ“Š ç›‘æ§å’Œå‘Šè­¦

#### ç³»ç»Ÿç›‘æ§
```python
class SystemMonitor:
    def __init__(self):
        self.metrics = {
            "requests_total": 0,
            "requests_failed": 0,
            "response_times": [],
            "active_connections": 0
        }
    
    def record_request(self, success: bool, response_time: float):
        """è®°å½•è¯·æ±‚æŒ‡æ ‡"""
        self.metrics["requests_total"] += 1
        if not success:
            self.metrics["requests_failed"] += 1
        
        self.metrics["response_times"].append(response_time)
        
        # ä¿æŒæœ€è¿‘1000ä¸ªå“åº”æ—¶é—´è®°å½•
        if len(self.metrics["response_times"]) > 1000:
            self.metrics["response_times"] = self.metrics["response_times"][-1000:]
    
    def get_health_status(self):
        """è·å–å¥åº·çŠ¶æ€"""
        if not self.metrics["response_times"]:
            return {"status": "unknown", "message": "æš‚æ— æ•°æ®"}
        
        avg_response_time = sum(self.metrics["response_times"]) / len(self.metrics["response_times"])
        error_rate = self.metrics["requests_failed"] / max(self.metrics["requests_total"], 1)
        
        if avg_response_time > 5.0 or error_rate > 0.1:
            return {"status": "unhealthy", "message": "æ€§èƒ½å¼‚å¸¸"}
        elif avg_response_time > 2.0 or error_rate > 0.05:
            return {"status": "degraded", "message": "æ€§èƒ½ä¸‹é™"}
        else:
            return {"status": "healthy", "message": "è¿è¡Œæ­£å¸¸"}

# å…¨å±€ç›‘æ§å®ä¾‹
system_monitor = SystemMonitor()
```

#### å‘Šè­¦é€šçŸ¥
```python
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart

class AlertManager:
    def __init__(self, smtp_server, smtp_port, username, password):
        self.smtp_server = smtp_server
        self.smtp_port = smtp_port
        self.username = username
        self.password = password
        self.alert_history = {}
    
    def send_alert(self, level: str, message: str, details: dict = None):
        """å‘é€å‘Šè­¦"""
        alert_key = f"{level}:{message}"
        
        # é˜²æ­¢é‡å¤å‘Šè­¦ï¼ˆ1å°æ—¶å†…ç›¸åŒå‘Šè­¦åªå‘é€ä¸€æ¬¡ï¼‰
        now = time.time()
        if alert_key in self.alert_history:
            if now - self.alert_history[alert_key] < 3600:
                return
        
        self.alert_history[alert_key] = now
        
        # å‘é€é‚®ä»¶å‘Šè­¦
        try:
            self._send_email_alert(level, message, details)
        except Exception as e:
            logger.error(f"å‘é€å‘Šè­¦é‚®ä»¶å¤±è´¥: {e}")
    
    def _send_email_alert(self, level: str, message: str, details: dict):
        """å‘é€é‚®ä»¶å‘Šè­¦"""
        msg = MIMEMultipart()
        msg['From'] = self.username
        msg['To'] = "admin@example.com"  # é…ç½®ç®¡ç†å‘˜é‚®ç®±
        msg['Subject'] = f"[{level.upper()}] K12è‹±è¯­çŸ¥è¯†å›¾è°±ç³»ç»Ÿå‘Šè­¦"
        
        body = f"""
        å‘Šè­¦çº§åˆ«: {level}
        å‘Šè­¦æ¶ˆæ¯: {message}
        å‘ç”Ÿæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
        
        è¯¦ç»†ä¿¡æ¯:
        {json.dumps(details, indent=2, ensure_ascii=False) if details else 'æ— '}
        """
        
        msg.attach(MIMEText(body, 'plain', 'utf-8'))
        
        with smtplib.SMTP(self.smtp_server, self.smtp_port) as server:
            server.starttls()
            server.login(self.username, self.password)
            server.send_message(msg)
```

### ğŸ”§ è°ƒè¯•å·¥å…·

#### æ€§èƒ½åˆ†æå™¨
```python
import cProfile
import pstats
from contextlib import contextmanager

@contextmanager
def profile_code(sort_by='cumulative', limit=20):
    """ä»£ç æ€§èƒ½åˆ†æä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
    profiler = cProfile.Profile()
    profiler.enable()
    
    try:
        yield profiler
    finally:
        profiler.disable()
        stats = pstats.Stats(profiler)
        stats.sort_stats(sort_by)
        stats.print_stats(limit)

# ä½¿ç”¨ç¤ºä¾‹
with profile_code():
    result = ai_agent_service.batch_auto_annotate(questions)
```

#### æ•°æ®åº“æŸ¥è¯¢åˆ†æ
```python
def analyze_cypher_query(cypher: str, params: dict = None):
    """åˆ†æCypheræŸ¥è¯¢æ€§èƒ½"""
    with neo4j_service.driver.session() as session:
        # è·å–æŸ¥è¯¢è®¡åˆ’
        explain_result = session.run(f"EXPLAIN {cypher}", params or {})
        plan = explain_result.consume().plan
        
        # è·å–æŸ¥è¯¢ç»Ÿè®¡
        profile_result = session.run(f"PROFILE {cypher}", params or {})
        profile = profile_result.consume().profile
        
        analysis = {
            "estimated_rows": plan.get("EstimatedRows", 0),
            "db_hits": profile.get("DbHits", 0),
            "page_cache_hits": profile.get("PageCacheHits", 0),
            "page_cache_misses": profile.get("PageCacheMisses", 0),
            "execution_time": profile.get("Time", 0)
        }
        
        # æ€§èƒ½å»ºè®®
        recommendations = []
        if analysis["db_hits"] > 1000:
            recommendations.append("è€ƒè™‘æ·»åŠ ç´¢å¼•ä»¥å‡å°‘æ•°æ®åº“è®¿é—®")
        if analysis["page_cache_misses"] > analysis["page_cache_hits"]:
            recommendations.append("ç¼“å­˜å‘½ä¸­ç‡ä½ï¼Œè€ƒè™‘å¢åŠ å†…å­˜")
        
        analysis["recommendations"] = recommendations
        return analysis
```

---

## ğŸ“ æŠ€æœ¯æ”¯æŒ

### ğŸ¤ è·å–å¸®åŠ©
- **æ–‡æ¡£**: æŸ¥çœ‹README.mdå’ŒINSTALL.md
- **æ—¥å¿—**: æ£€æŸ¥logs/ç›®å½•ä¸‹çš„æ—¥å¿—æ–‡ä»¶
- **æµ‹è¯•**: è¿è¡Œtestè„šæœ¬è¯Šæ–­é—®é¢˜
- **ç¤¾åŒº**: æäº¤Issueåˆ°GitHubä»“åº“

### ğŸ”„ ç‰ˆæœ¬æ›´æ–°
```bash
# æ‹‰å–æœ€æ–°ä»£ç 
git pull origin main

# æ›´æ–°ä¾èµ–
pip install -r requirements.txt --upgrade

# è¿è¡Œæ•°æ®åº“è¿ç§»ï¼ˆå¦‚æœ‰ï¼‰
python scripts/migrate_database.py

# é‡å¯æœåŠ¡
sudo systemctl restart knowledge-graph
```

### ğŸ“Š æ€§èƒ½åŸºå‡†
- **å•ä¸ªé¢˜ç›®æ ‡æ³¨**: < 500ms
- **æ‰¹é‡æ ‡æ³¨**: > 10 questions/second
- **APIå“åº”æ—¶é—´**: < 1s (95th percentile)
- **æ•°æ®åº“æŸ¥è¯¢**: < 100ms (ç®€å•æŸ¥è¯¢)
- **å†…å­˜ä½¿ç”¨**: < 2GB (1000é¢˜ç›® + 100çŸ¥è¯†ç‚¹)

---

è¿™ä»½å¼€å‘æ–‡æ¡£æ¶µç›–äº†ç³»ç»Ÿçš„æ–¹æ–¹é¢é¢ï¼Œä»æ¶æ„è®¾è®¡åˆ°éƒ¨ç½²è¿ç»´ï¼Œä¸ºå¼€å‘è€…æä¾›äº†å…¨é¢çš„æŠ€æœ¯æŒ‡å—ã€‚éšç€é¡¹ç›®çš„å‘å±•ï¼Œå»ºè®®æŒç»­æ›´æ–°å’Œå®Œå–„è¿™ä»½æ–‡æ¡£ã€‚
