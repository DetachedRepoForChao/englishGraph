#!/usr/bin/env python3
"""
ä½¿ç”¨å¼€æºè¯åº“å¢å¼ºå…³é”®è¯åº“
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from backend.services.wordnet_enhancer import WordNetEnhancer
from backend.services.nlp_service import NLPService
import json
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def enhance_keywords():
    """å¢å¼ºå…³é”®è¯åº“"""
    print("ğŸš€ å¼€å§‹ä½¿ç”¨å¼€æºè¯åº“å¢å¼ºå…³é”®è¯...")
    
    # åˆå§‹åŒ–å¢å¼ºå™¨
    enhancer = WordNetEnhancer()
    
    # å½“å‰çš„å…³é”®è¯æ¨¡å¼
    current_patterns = {
        "ä¸€èˆ¬ç°åœ¨æ—¶": [
            "always", "usually", "often", "sometimes", "never",
            "every day", "every week", "every month", "every year",
            "æ€»æ˜¯", "é€šå¸¸", "ç»å¸¸", "æœ‰æ—¶", "ä»ä¸", "æ¯å¤©", "æ¯å‘¨", "æ¯æœˆ", "æ¯å¹´",
            "ç¬¬ä¸‰äººç§°å•æ•°", "åŠ¨è¯åŸå½¢", "does", "do", "goes", "plays", "works", "studies",
            "_____ to", "_____ every", "_____ always", "_____ usually",
            "A) go B) goes", "go/goes", "ç¬¬ä¸‰äººç§°å•æ•°å½¢å¼", "åŠ¨è¯å½¢å¼é€‰æ‹©"
        ],
        "ç°åœ¨è¿›è¡Œæ—¶": [
            "now", "at the moment", "at present", "currently", "right now", "look!", "listen!",
            "ç°åœ¨", "æ­£åœ¨", "æ­¤åˆ»", "ç›®å‰", "ç°åœ¨è¿›è¡Œæ—¶",
            "am doing", "is doing", "are doing", "am playing", "is playing", "are playing",
            "am working", "is working", "are working", "am studying", "is studying", "are studying",
            "_____ playing", "_____ working", "_____ studying", "A) play B) plays C) are playing",
            "beåŠ¨è¯+ç°åœ¨åˆ†è¯", "ingå½¢å¼", "è¿›è¡Œæ—¶æ€", "playing", "working", "studying"
        ],
        "ç°åœ¨å®Œæˆæ—¶": [
            "already", "yet", "just", "ever", "never", "since", "for",
            "å·²ç»", "è¿˜", "åˆšåˆš", "æ›¾ç»", "ä»æœª", "è‡ªä»", "æŒç»­",
            "have", "has", "è¿‡å»åˆ†è¯", "finished", "done", "lived", "been"
        ],
        "ä¸€èˆ¬è¿‡å»æ—¶": [
            "yesterday", "last week", "last month", "last year", "ago",
            "æ˜¨å¤©", "ä¸Šå‘¨", "ä¸Šä¸ªæœˆ", "å»å¹´", "ä»¥å‰", "è¿‡å»",
            "åŠ¨è¯è¿‡å»å¼", "was", "were", "did", "went", "played", "worked", "studied"
        ],
        "è¢«åŠ¨è¯­æ€": [
            "beåŠ¨è¯", "è¿‡å»åˆ†è¯", "by", "è¢«åŠ¨", "passive voice",
            "was cleaned", "were written", "is made", "are done",
            "was written", "were cleaned", "by someone"
        ],
        "å®šè¯­ä»å¥": [
            "which", "that", "who", "whom", "whose", "where", "when",
            "å…³ç³»ä»£è¯", "å…³ç³»å‰¯è¯", "å…ˆè¡Œè¯", "ä»å¥", "the man who", "the book which"
        ],
        "å®¾è¯­ä»å¥": [
            "that", "whether", "if", "what", "when", "where", "why", "how",
            "å®¾è¯­ä»å¥", "å¼•å¯¼è¯", "é™ˆè¿°è¯­åº", "tell me", "ask", "wonder", "know"
        ],
        "æ¯”è¾ƒçº§å’Œæœ€é«˜çº§": [
            "than", "more", "most", "less", "least", "-er", "-est",
            "æ¯”è¾ƒçº§", "æœ€é«˜çº§", "æ›´", "æœ€",
            "better", "best", "worse", "worst", "bigger", "biggest",
            "more beautiful", "most beautiful", "sweeter", "sweetest"
        ]
    }
    
    print(f"ğŸ“š å½“å‰å…³é”®è¯åº“åŒ…å« {len(current_patterns)} ä¸ªçŸ¥è¯†ç‚¹")
    
    # å¢å¼ºå…³é”®è¯åº“
    enhanced_patterns = enhancer.generate_enhanced_keyword_patterns(current_patterns)
    
    # ç»Ÿè®¡å¢å¼ºæ•ˆæœ
    total_original = sum(len(keywords) for keywords in current_patterns.values())
    total_enhanced = sum(len(keywords) for keywords in enhanced_patterns.values())
    
    print(f"\nğŸ“Š å¢å¼ºæ•ˆæœç»Ÿè®¡:")
    print(f"åŸå§‹å…³é”®è¯æ€»æ•°: {total_original}")
    print(f"å¢å¼ºåå…³é”®è¯æ€»æ•°: {total_enhanced}")
    print(f"å¢åŠ å…³é”®è¯æ•°é‡: {total_enhanced - total_original}")
    print(f"å¢é•¿ç‡: {((total_enhanced - total_original) / total_original * 100):.1f}%")
    
    # æ˜¾ç¤ºæ¯ä¸ªçŸ¥è¯†ç‚¹çš„å¢å¼ºæƒ…å†µ
    print(f"\nğŸ¯ å„çŸ¥è¯†ç‚¹å¢å¼ºè¯¦æƒ…:")
    for kp, enhanced_keywords in enhanced_patterns.items():
        original_count = len(current_patterns[kp])
        enhanced_count = len(enhanced_keywords)
        print(f"  {kp}: {original_count} â†’ {enhanced_count} (+{enhanced_count - original_count})")
    
    # ä¿å­˜å¢å¼ºåçš„å…³é”®è¯åº“
    output_file = "enhanced_keyword_patterns.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(enhanced_patterns, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ å¢å¼ºåçš„å…³é”®è¯åº“å·²ä¿å­˜åˆ°: {output_file}")
    
    # æ˜¾ç¤ºä¸€äº›å¢å¼ºç¤ºä¾‹
    print(f"\nğŸ” å¢å¼ºç¤ºä¾‹:")
    for kp in ["ç°åœ¨è¿›è¡Œæ—¶", "ä¸€èˆ¬ç°åœ¨æ—¶"]:
        if kp in enhanced_patterns:
            original = set(current_patterns[kp])
            enhanced = set(enhanced_patterns[kp])
            new_keywords = enhanced - original
            print(f"\n{kp} æ–°å¢å…³é”®è¯ (å‰10ä¸ª):")
            for keyword in list(new_keywords)[:10]:
                print(f"  + {keyword}")
    
    return enhanced_patterns

def test_enhanced_keywords():
    """æµ‹è¯•å¢å¼ºåçš„å…³é”®è¯æ•ˆæœ"""
    print("\nğŸ§ª æµ‹è¯•å¢å¼ºåçš„å…³é”®è¯æ•ˆæœ...")
    
    # è¿™é‡Œå¯ä»¥æ·»åŠ æµ‹è¯•é€»è¾‘
    # ä¾‹å¦‚ï¼šä½¿ç”¨å¢å¼ºåçš„å…³é”®è¯åº“è¿›è¡Œæ ‡æ³¨æµ‹è¯•
    
    test_questions = [
        "Look! The children are playing in the playground.",
        "I have already finished my homework.",
        "She goes to school every day.",
        "The book which is on the table belongs to me."
    ]
    
    print("æµ‹è¯•é¢˜ç›®:")
    for i, question in enumerate(test_questions, 1):
        print(f"{i}. {question}")

if __name__ == "__main__":
    try:
        enhanced_patterns = enhance_keywords()
        test_enhanced_keywords()
        print("\nâœ… å…³é”®è¯å¢å¼ºå®Œæˆï¼")
    except Exception as e:
        print(f"\nâŒ å…³é”®è¯å¢å¼ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
